{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superb-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from efficientnet.tfkeras import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confused-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-keyboard",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structured-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet_model = EfficientNetB3(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informed-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_input = tf.keras.layers.Input(shape=(1000,))\n",
    "\n",
    "# Encoder input\n",
    "encoder_input = tf.keras.layers.Input(shape=(256, 256, 1))\n",
    "encoder = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=(2, 2))(encoder_input)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(128, (3, 3), padding='same', strides=(2, 2))(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(256, (3, 3), padding='same', strides=(2, 2))(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(512, (3, 3), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(512, (3, 3), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Activation('relu')(encoder)\n",
    "\n",
    "# Fusion\n",
    "fusion_output = tf.keras.layers.RepeatVector(32 * 32)(embed_input)\n",
    "fusion_output = tf.keras.layers.Reshape(([32, 32, 1000]))(fusion_output)\n",
    "fusion_output = tf.keras.layers.concatenate([encoder, fusion_output], axis=3)\n",
    "fusion_output = tf.keras.layers.Conv2D(256, (1, 1), padding='same')(fusion_output)\n",
    "fusion_output = tf.keras.layers.Activation('relu')(fusion_output)\n",
    "\n",
    "# Decoder\n",
    "decoder_output = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(fusion_output)\n",
    "decoder_output = tf.keras.layers.Activation('relu')(decoder_output)\n",
    "decoder_output = tf.keras.layers.UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Activation('relu')(decoder_output)\n",
    "decoder_output = tf.keras.layers.UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Activation('relu')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Conv2D(16, (3, 3), padding='same')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Activation('relu')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Conv2D(2, (3, 3), padding='same')(decoder_output)\n",
    "decoder_output = tf.keras.layers.Activation('tanh')(decoder_output)\n",
    "decoder_output = tf.keras.layers.UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unique-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 640         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 128 73856       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 128 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  147584      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 256)  295168      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 256)  590080      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 256)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 512)  1180160     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 512)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  2359808     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 512)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  1179904     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 1024, 1000)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 32, 1000) 0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1256) 0           activation_7[0][0]               \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  321792      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  295040      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 128)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 64)   73792       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 32) 18464       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 32) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 16) 4624        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 16) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 2)  290         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 2)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 2)  0           activation_13[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,541,202\n",
      "Trainable params: 6,541,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elementary-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-mechanism",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "orange-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(image_path):\n",
    "    byte_img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img_norm = tf.cast(img, tf.float32)\n",
    "    img_norm = img_norm / 255.\n",
    "    \n",
    "    img = tf.image.resize(img, (300, 300))\n",
    "    img = img / 255.\n",
    "    img_expanded = tf.expand_dims(img, axis=0)\n",
    "    embeddings = tf.squeeze(effnet_model(img_expanded), axis=0)\n",
    "    \n",
    "    lab_img = tfio.experimental.color.rgb_to_lab(img_norm)\n",
    "    \n",
    "    l_img = tf.expand_dims(lab_img[:, :, 0], axis=2)\n",
    "    ab_img = lab_img[:, :, 1:] / 128.\n",
    "    \n",
    "    return {'input_1': l_img, 'input_2': embeddings}, ab_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earned-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('data/images/Train/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "certified-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images = train_test_split(images, test_size=0.4, random_state=2021)\n",
    "validation_images, test_images = train_test_split(validation_images, test_size=0.5, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tracked-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_data = train_data.map(get_data)\n",
    "train_data = train_data.batch(batch_size)\n",
    "train_data = train_data.shuffle(len(train_images))\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_data = tf.data.Dataset.from_tensor_slices(validation_images)\n",
    "validation_data = validation_data.map(get_data)\n",
    "validation_data = validation_data.batch(batch_size)\n",
    "validation_data = validation_data.cache()\n",
    "validation_data = validation_data.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-arbor",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data, epochs=epochs, validation_data=validation_data,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model/'):\n",
    "    os.makedirs('model')\n",
    "    \n",
    "model.save('model/effnet_colorizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-david",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "received-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        if name == 'L':\n",
    "            plt.imshow(image, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "turkish-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lab_img(img_shape, l_color, ab_color):\n",
    "    lab_image = np.zeros(img_shape)\n",
    "    lab_image[:, :, 0] = l_color\n",
    "    lab_image[:, :, 1:] = ab_color\n",
    "    \n",
    "    return lab_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efficient-counter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-1aeb56f989b7>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-1aeb56f989b7>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    colorized_image =\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for test_image in np.random.choice(test_images, size=6):\n",
    "    img = tf.io.decode_jpeg(tf.io.read_file(test_image))\n",
    "    img_norm = tf.cast(img, tf.float32)\n",
    "    img_norm = img_norm / 255.\n",
    "    \n",
    "    lab_img = tfio.experimental.color.rgb_to_lab(img_norm)\n",
    "    l_img = lab_img[:, :, 0]\n",
    "    \n",
    "    img_resized = tf.image.resize(img, (300, 300))\n",
    "    img_resized = img_resized / 255.\n",
    "    embeddings = effnet_model.predict(tf.expand_dims(img_resized, axis=0))\n",
    "    pred_ab = model.predict([tf.expand_dims(l_img, axis=0), embeddings])\n",
    "    \n",
    "    lab_image = fill_lab_img(img.shape, l_img, pred_ab)\n",
    "    colorized_image = \n",
    "    visualize(\n",
    "        ori_img=img, l_img=l_img\n",
    "    )\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
